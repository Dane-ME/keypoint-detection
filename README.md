# Multi-Person Keypoint Detection

ThÆ° viá»‡n deep learning cho phÃ¡t hiá»‡n keypoint Ä‘a ngÆ°á»i sá»­ dá»¥ng PyTorch, vá»›i kiáº¿n trÃºc MobileNetV3 tÃ¹y chá»‰nh vÃ  há»‡ thá»‘ng cÃ¢n báº±ng loss function tiÃªn tiáº¿n.

## Tá»•ng quan dá»± Ã¡n

Dá»± Ã¡n nÃ y lÃ  má»™t há»‡ thá»‘ng AI hoÃ n chá»‰nh Ä‘á»ƒ phÃ¡t hiá»‡n vÃ  Ä‘á»‹nh vá»‹ cÃ¡c Ä‘iá»ƒm khá»›p (keypoints) trÃªn cÆ¡ thá»ƒ ngÆ°á»i trong áº£nh. Há»‡ thá»‘ng cÃ³ thá»ƒ xá»­ lÃ½ nhiá»u ngÆ°á»i trong cÃ¹ng má»™t áº£nh vÃ  xÃ¡c Ä‘á»‹nh 17 Ä‘iá»ƒm khá»›p chÃ­nh trÃªn cÆ¡ thá»ƒ má»—i ngÆ°á»i.

## TÃ­nh nÄƒng chÃ­nh

- **PhÃ¡t hiá»‡n keypoint Ä‘a ngÆ°á»i**: XÃ¡c Ä‘á»‹nh 17 Ä‘iá»ƒm khá»›p cho má»—i ngÆ°á»i trong áº£nh
- **Backbone MobileNetV3 tá»‘i Æ°u**: ÄÆ°á»£c tÃ¹y chá»‰nh cho thiáº¿t bá»‹ di Ä‘á»™ng
- **Há»‡ thá»‘ng loss function tiÃªn tiáº¿n**:
  - Dynamic loss balancing - giáº£i quyáº¿t váº¥n Ä‘á» PCK metrics Ä‘Ã¬nh trá»‡
  - Spatial-aware coordinate loss - tÄƒng cÆ°á»ng trá»ng sá»‘ lá»—i pixel-space
  - Adaptive heatmap loss - trá»ng sá»‘ theo vÃ¹ng Ä‘á»ƒ Ä‘á»‹nh vá»‹ keypoint tá»‘t hÆ¡n
- **Person detection vá»›i NMS**: PhÃ¡t hiá»‡n ngÆ°á»i vÃ  loáº¡i bá» duplicate
- **Há»‡ thá»‘ng cáº¥u hÃ¬nh linh hoáº¡t**: Sá»­ dá»¥ng file YAML
- **Metrics Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n**: PCK, ADE vÃ  cÃ¡c chá»‰ sá»‘ khÃ¡c
- **Quáº£n lÃ½ thiáº¿t bá»‹ máº¡nh máº½**: Há»— trá»£ CPU/GPU vá»›i error handling

## Cáº¥u trÃºc dá»± Ã¡n chi tiáº¿t

```
keypoint-detection/
â”œâ”€â”€ dll/                           # Package chÃ­nh
â”‚   â”œâ”€â”€ __init__.py               # Main exports
â”‚   â”œâ”€â”€ configs/                  # Há»‡ thá»‘ng cáº¥u hÃ¬nh
â”‚   â”‚   â”œâ”€â”€ base_config.py       # Base configuration classes
â”‚   â”‚   â”œâ”€â”€ model_config.py      # Model architecture config
â”‚   â”‚   â”œâ”€â”€ training_config.py   # Training hyperparameters
â”‚   â”‚   â”œâ”€â”€ dataset_config.py    # Dataset configuration
â”‚   â”‚   â””â”€â”€ config_loader.py     # YAML config loader
â”‚   â”œâ”€â”€ data/                     # Data processing pipeline
â”‚   â”‚   â”œâ”€â”€ dataloader.py        # Optimized dataset & dataloader
â”‚   â”‚   â”œâ”€â”€ augmentation.py      # Keypoint-aware augmentations
â”‚   â”‚   â””â”€â”€ transforms.py        # Image transformations
â”‚   â”œâ”€â”€ losses/                   # Advanced loss functions
â”‚   â”‚   â””â”€â”€ keypoint_loss.py     # Dynamic loss balancing
â”‚   â”œâ”€â”€ models/                   # Neural network architecture
â”‚   â”‚   â”œâ”€â”€ keypoint_model.py    # Main multi-person model
â”‚   â”‚   â”œâ”€â”€ backbone.py          # MobileNetV3 backbone
â”‚   â”‚   â”œâ”€â”€ person_head.py       # Person detection head
â”‚   â”‚   â”œâ”€â”€ keypoint_head.py     # Keypoint regression head
â”‚   â”‚   â””â”€â”€ heatmap_head.py      # Heatmap generation head
â”‚   â”œâ”€â”€ training/                 # Training system
â”‚   â”‚   â””â”€â”€ trainer.py           # Training loop & optimization
â”‚   â”œâ”€â”€ utils/                    # Utility functions
â”‚   â”‚   â”œâ”€â”€ device_manager.py    # Hardware management
â”‚   â”‚   â”œâ”€â”€ logger.py            # Logging system
â”‚   â”‚   â””â”€â”€ metric.py            # Evaluation metrics
â”‚   â””â”€â”€ visualization/            # Analysis tools
â”‚       â””â”€â”€ backbone_vis.py      # Model visualization
â”œâ”€â”€ scripts/                      # Execution scripts
â”‚   â”œâ”€â”€ train.py                 # Training script
â”‚   â””â”€â”€ predict.py               # Inference script
â”œâ”€â”€ configs/                      # Configuration files
â”‚   â””â”€â”€ default_config.yaml      # Default settings
â”œâ”€â”€ outputs/                      # Training outputs
â”‚   â”œâ”€â”€ best_model.pth           # Best model checkpoint
â”‚   â””â”€â”€ training.log             # Training logs
â””â”€â”€ setup.py                     # Package installation
```

## Kiáº¿n trÃºc há»‡ thá»‘ng

### ğŸ§  Model Architecture
- **Backbone**: MobileNetV3-Small tá»‘i Æ°u cho mobile
- **Person Detection**: PERSON_HEAD vá»›i NMS
- **Keypoint Detection**: Dual-head architecture (heatmap + regression)
- **Attention Mechanism**: Channel attention cho feature enhancement

### ğŸ“Š Data Pipeline
- **Dataset**: OptimizedKeypointsDataset vá»›i LRU caching
- **Augmentation**: Keypoint-aware transformations
- **Batching**: Adaptive batch sampler theo sá»‘ ngÆ°á»i
- **Format**: COCO-style 17 keypoints

### ğŸ¯ Loss Functions
- **Keypoint Loss**: MSE vá»›i spatial weighting
- **Visibility Loss**: Binary classification
- **Heatmap Loss**: Gaussian heatmap regression
- **Dynamic Balancing**: Adaptive loss weights

## ğŸ› ï¸ CÃ´ng cá»¥ vÃ  Dependencies

### Core Dependencies
| Package | PhiÃªn báº£n | Chá»©c nÄƒng | Táº¡i sao sá»­ dá»¥ng |
|---------|-----------|-----------|-----------------|
| **torch** | Latest stable | Deep learning framework | Industry standard, GPU support, research-friendly |
| **torchvision** | Compatible | Computer vision ops | Integrated vá»›i PyTorch, optimized operations |
| **numpy** | Latest stable | Numerical computing | Fast numerical operations, scientific computing |
| **PIL (Pillow)** | Latest stable | Image processing | Standard image library, format support |
| **opencv-python** | Latest stable | Advanced CV ops | Advanced CV operations, video processing |
| **pyyaml** | Latest stable | Config parsing | Human-readable config, easy editing |
| **tqdm** | Latest stable | Progress bars | User experience, training monitoring |

### Development Tools
- **pandas + openpyxl**: Documentation export, data analysis
- **matplotlib**: Visualization vÃ  plotting
- **dataclasses**: Type-safe configuration classes
- **pathlib**: Cross-platform path handling
- **logging**: Production-ready logging system

## ğŸ“¦ Installation

### 1. Clone repository
```bash
git clone https://github.com/your_username/Multi-Person-Keypoint-Detection.git
cd keypoint-detection
```

### 2. Táº¡o virtual environment
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

### 3. CÃ i Ä‘áº·t dependencies
```bash
# CÃ i Ä‘áº·t tá»« setup.py
pip install -e .

# Hoáº·c cÃ i Ä‘áº·t manual
pip install torch torchvision numpy pillow opencv-python pyyaml tqdm pandas openpyxl
```

## ğŸš€ Sá»­ dá»¥ng

### Training Model
```bash
python scripts/train.py \
    --config configs/default_config.yaml \
    --data-dir path/to/dataset \
    --output-dir path/to/output \
    [--resume path/to/checkpoint.pth]
```

### Inference
```bash
python scripts/predict.py \
    --image path/to/image.jpg \
    --checkpoint path/to/checkpoint.pth
```

### Programmatic Usage
```python
from dll import MultiPersonKeypointModel, ModelConfig, TrainingConfig
from dll.data import create_optimized_dataloader

# Load model
model = MultiPersonKeypointModel(model_config, training_config)

# Create dataloader
dataloader = create_optimized_dataloader(
    dataset_dir="path/to/data",
    batch_size=32,
    split="train"
)

# Training
from dll.training import Trainer
trainer = Trainer(model, device, train_dataloader, val_dataloader, config)
trained_model, history = trainer.train()
```

## âš™ï¸ Configuration System

Há»‡ thá»‘ng cáº¥u hÃ¬nh linh hoáº¡t vá»›i YAML files:

### Cáº¥u hÃ¬nh chÃ­nh (default_config.yaml)
```yaml
# Device configuration
device:
  type: 'auto'              # auto, cuda, cpu
  mixed_precision: true     # AMP training
  pin_memory: true         # Faster data transfer

# Model architecture
model:
  backbone:
    width_mult: 1.5         # Model capacity
    in_channels: 1          # Grayscale input
    out_channels: 128       # Feature dimensions

  keypoint_head:
    num_keypoints: 17       # COCO format
    dropout_rate: 0.2       # Regularization

  heatmap_head:
    heatmap_size: [56, 56]  # Spatial resolution
    use_attention: true     # Channel attention

# Training hyperparameters
training:
  num_epochs: 30
  batch_size: 128
  pck_thresholds: [0.002, 0.05, 0.2]  # Evaluation metrics

  optimizer:
    name: "adam"
    learning_rate: 0.01
    weight_decay: 0.001

  lr_scheduler:
    factor: 0.1             # LR reduction factor
    patience: 3             # Epochs to wait
    min_lr: 1e-6           # Minimum LR

  loss:
    keypoint_loss_weight: 20.0    # Loss balancing
    visibility_loss_weight: 8.0
    focal_gamma: 2.5              # Focal loss params
```

### Configuration Classes
- **ModelConfig**: Architecture parameters
- **TrainingConfig**: Training hyperparameters
- **DeviceConfig**: Hardware settings
- **AugmentationConfig**: Data augmentation policies

## Dataset Format

Organize your dataset as follows:

```
dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â””â”€â”€ val/
    â”œâ”€â”€ images/
    â””â”€â”€ labels/
```

- **Images:** Store image files (e.g., JPEG, PNG) in the `images/` folder.
- **Labels:** Store annotation files in the `labels/` folder (e.g., YOLO format).

## ğŸ—ï¸ Model Architecture Chi tiáº¿t

### Backbone Network
- **MobileNetV3-Small**: Tá»‘i Æ°u cho mobile devices
- **Width Multiplier**: Äiá»u chá»‰nh model capacity (0.5-2.0)
- **Channel Attention**: Focus vÃ o features quan trá»ng
- **Grayscale Support**: Giáº£m computational cost

### Multi-Head Architecture
1. **Person Detection Head**
   - Detect person bounding boxes
   - Confidence scoring
   - Non-Maximum Suppression (NMS)

2. **Heatmap Head**
   - Generate spatial heatmaps cho má»—i keypoint
   - Gaussian-based target generation
   - Deconvolutional upsampling

3. **Keypoint Regression Head**
   - Direct coordinate prediction
   - Visibility classification
   - Fine-grained localization

### Advanced Features
- **ROI Align**: Extract person-specific features
- **Dynamic Loss Balancing**: Adaptive loss weights
- **Spatial Attention**: Focus on keypoint regions
- **Mixed Precision**: Faster training vá»›i AMP

## ğŸ“Š Evaluation Metrics

| Metric | CÃ´ng thá»©c | Threshold/Range | Ã nghÄ©a |
|--------|-----------|-----------------|---------|
| **PCK** | (correct_keypoints / total_keypoints) Ã— 100 | 0.002, 0.05, 0.2 | Accuracy of keypoint localization |
| **ADE** | Mean Euclidean distance | Pixels (lower better) | Average pixel error |
| **Training Loss** | Weighted sum of components | Positive real | Overall performance |
| **Keypoint Loss** | MSE coordinates | Positive real | Coordinate accuracy |
| **Visibility Loss** | Binary cross entropy | Positive real | Visibility classification |
| **Heatmap Loss** | MSE heatmaps | Positive real | Spatial representation |

### Loss Function Components
```python
total_loss = (
    keypoint_weight * keypoint_loss +
    visibility_weight * visibility_loss +
    heatmap_weight * heatmap_loss
)
```

### Training Monitoring
- **Learning Rate**: Adaptive scheduling (0.01 â†’ 1e-6)
- **Gradient Norm**: Clipped to max_norm=1.0
- **Early Stopping**: Patience=10 epochs
- **Checkpointing**: Best model auto-save

## ï¿½ API Reference - Chi tiáº¿t Functions vÃ  Classes

### 1. **MultiPersonKeypointModel** - Model chÃ­nh

#### Constructor
```python
def __init__(self, config: ModelConfig, training_config: TrainingConfig):
    """
    Khá»Ÿi táº¡o model vá»›i cáº¥u hÃ¬nh.

    Args:
        config: ModelConfig - Cáº¥u hÃ¬nh kiáº¿n trÃºc model
        training_config: TrainingConfig - Cáº¥u hÃ¬nh training
    """
```

#### Forward Pass
```python
def forward(self, batch) -> Dict[str, torch.Tensor]:
    """
    Forward pass cá»§a model.

    Args:
        batch: Dict hoáº·c Tensor
            - Náº¿u Dict: {'image': Tensor[B,C,H,W], 'bboxes': List, ...}
            - Náº¿u Tensor: Images [B,C,H,W]

    Returns:
        Dict chá»©a:
            - 'keypoints': Tensor[B,N,17,2] - Tá»a Ä‘á»™ keypoints
            - 'visibilities': Tensor[B,N,17] - Visibility scores
            - 'heatmap': Tensor[B,17,H,W] - Heatmaps
            - 'loss': Scalar - Training loss (náº¿u cÃ³ targets)
    """
```

#### Training Step
```python
def train_step(self, batch: Dict[str, torch.Tensor],
               optimizer: torch.optim.Optimizer) -> Dict[str, float]:
    """
    Thá»±c hiá»‡n má»™t bÆ°á»›c training.

    Args:
        batch: Batch data vá»›i keys ['image', 'keypoints', 'visibilities']
        optimizer: PyTorch optimizer

    Returns:
        Dict metrics: {'loss', 'keypoint_loss', 'visibility_loss', 'num_detections'}
    """
```

#### Validation Step
```python
def validation_step(self, batch: Dict[str, torch.Tensor]) -> Dict[str, float]:
    """
    Thá»±c hiá»‡n validation step.

    Args:
        batch: Validation batch data

    Returns:
        Dict metrics bao gá»“m PCK@multiple thresholds vÃ  ADE
    """
```

### 2. **OptimizedKeypointsDataset** - Dataset Class

#### Constructor
```python
def __init__(self,
             dataset_dir: str,
             split: str = "train",
             img_size: int = 512,
             grayscale: bool = False,
             num_keypoints: int = 17,
             heatmap_size: Tuple[int, int] = (56, 56),
             transform: Optional[ITransform] = None,
             augmentation: Optional[KeypointAugmentation] = None,
             max_persons: int = 10,
             enable_caching: bool = True,
             cache_size: int = 1000):
    """
    Khá»Ÿi táº¡o optimized dataset.

    Args:
        dataset_dir: ÄÆ°á»ng dáº«n Ä‘áº¿n dataset
        split: "train" hoáº·c "val"
        img_size: KÃ­ch thÆ°á»›c resize image
        grayscale: Convert sang grayscale
        num_keypoints: Sá»‘ keypoints (17 cho COCO)
        heatmap_size: KÃ­ch thÆ°á»›c heatmap output
        transform: Image transformations
        augmentation: Data augmentation
        max_persons: Sá»‘ ngÆ°á»i tá»‘i Ä‘a per image
        enable_caching: Báº­t LRU cache
        cache_size: KÃ­ch thÆ°á»›c cache
    """
```

#### Get Item
```python
def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
    """
    Láº¥y má»™t sample tá»« dataset.

    Args:
        idx: Index cá»§a sample

    Returns:
        Dict chá»©a:
            - 'image': Tensor[C,H,W] - Processed image
            - 'keypoints': Tensor[N,17,2] - Keypoint coordinates
            - 'visibilities': Tensor[N,17] - Visibility flags
            - 'bboxes': Tensor[N,4] - Person bounding boxes
            - 'heatmaps': Tensor[17,H,W] - Target heatmaps
    """
```

### 3. **Trainer** - Training System

#### Constructor
```python
def __init__(self,
             model: nn.Module,
             device: torch.device,
             train_dataloader: DataLoader,
             val_dataloader: DataLoader,
             config: TrainingConfig,
             output_dir: Optional[Union[str, Path]] = None,
             use_amp: bool = False):
    """
    Khá»Ÿi táº¡o trainer.

    Args:
        model: Model cáº§n train
        device: Device (CPU/GPU)
        train_dataloader: Training dataloader
        val_dataloader: Validation dataloader
        config: Training configuration
        output_dir: ThÆ° má»¥c lÆ°u outputs
        use_amp: Sá»­ dá»¥ng Automatic Mixed Precision
    """
```

#### Train Method
```python
def train(self) -> Tuple[nn.Module, Dict]:
    """
    Thá»±c hiá»‡n training loop chÃ­nh.

    Returns:
        Tuple[trained_model, training_history]
            - trained_model: Model Ä‘Ã£ train
            - training_history: Dict chá»©a metrics theo epoch
    """
```

#### Save/Load Checkpoint
```python
def save_checkpoint(self, epoch: int, is_best: bool = False) -> None:
    """LÆ°u model checkpoint."""

def load_checkpoint(self, checkpoint_path: str) -> int:
    """
    Load checkpoint vÃ  resume training.

    Returns:
        start_epoch: Epoch Ä‘á»ƒ resume
    """
```

## ï¿½ğŸ“‹ TÃ³m táº¯t chá»©c nÄƒng

### Core Features
âœ… **Multi-person keypoint detection** - PhÃ¡t hiá»‡n 17 keypoints/ngÆ°á»i
âœ… **MobileNetV3 backbone** - Tá»‘i Æ°u cho mobile deployment
âœ… **Advanced loss functions** - Dynamic balancing, spatial weighting
âœ… **Flexible configuration** - YAML-based parameter management
âœ… **Production-ready** - Robust training, checkpointing, monitoring
âœ… **Hardware optimization** - CPU/GPU support, mixed precision

### Technical Highlights
ğŸ”¬ **Research-grade**: State-of-the-art loss balancing techniques
âš¡ **Performance**: Optimized data pipeline vá»›i caching
ğŸ› ï¸ **Maintainable**: Modular architecture, type-safe configs
ğŸ“Š **Comprehensive**: Full metrics suite (PCK, ADE, loss components)
ğŸ¯ **Accurate**: Dual-head architecture (heatmap + regression)

## ğŸ“š Documentation

- **ğŸ“Š Excel Documentation**: `Keypoint_Detection_Documentation.xlsx` - Chi tiáº¿t Ä‘áº§y Ä‘á»§ vá» modules, functions, configs
- **ğŸ“– README**: File nÃ y - HÆ°á»›ng dáº«n sá»­ dá»¥ng vÃ  tá»•ng quan
- **âš™ï¸ Config Files**: `configs/default_config.yaml` - Tham sá»‘ cáº¥u hÃ¬nh
- **ğŸ“ Code Comments**: Inline documentation trong source code

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“„ License

[Your License Here]

## ğŸ“ Contact & Support

- **Issues**: GitHub Issues cho bug reports
- **Discussions**: GitHub Discussions cho questions
- **Email**: [your-email@domain.com]

## ğŸ™ Acknowledgments

- PyTorch team cho excellent framework
- MobileNetV3 authors cho efficient architecture
- COCO dataset cho keypoint annotations
- Open source community

---

**Happy coding! ğŸš€**

*Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t triá»ƒn vá»›i má»¥c Ä‘Ã­ch nghiÃªn cá»©u vÃ  giÃ¡o dá»¥c trong lÄ©nh vá»±c Computer Vision vÃ  Human Pose Estimation.*